---
title: "Practical Machine Learning - Final Project"
date: "June 15, 2015"
output: html_document
---

##Load the data and packages
```{r,message=FALSE,warning=FALSE}
library(caret)
library(rpart)
library(randomForest)
```

Change "#DIV/0!" and "" all to NA
```{r}
mytrain <- read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!", ""))
mytest <- read.csv("pml-testing.csv",na.strings=c("NA","#DIV/0!", ""))
```

##Partitioning the data
```{r}
inTrain <- createDataPartition(y = mytrain$classe, p = 0.6, list = FALSE)
training <- mytrain[inTrain,]
testing <- mytrain[-inTrain,]
dim(training)
dim(testing)
```

##Data Cleaning

Remove all columns with *NA*

```{r}
training <- training[,colSums(is.na(training)) == 0]
testing <-  testing[,colSums(is.na(testing)) == 0]
mytest <- mytest[,colSums(is.na(mytest)) == 0]
```

I am going to remove the first column and fifth column because they are not necessarily useful.

```{r}
training <- training[,-c(1,5)]
testing <- testing[,-c(1,5)]
mytest <- mytest[,-c(1,5)]
```

##Ultilizing algorithm 

###Decision tree

```{r}
model1 <- rpart(classe ~ ., data = training)
predictions1 <- predict(model1, testing, type = "class")
confusionMatrix(predictions1, testing$classe)
```

The accuracy is not very high.

###Random Forest

```{r}
model2 <- randomForest(classe~., data = training)
predictions2 <- predict(model2, testing, type = "class")
confusionMatrix(predictions2, testing$classe)
```

Using this method, the accuracy turns out to be over 99% which is desirable.

Thus we are going to use this model for the second part of the project.


```{r,results='hide'}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
mytest$new_window <- factor(mytest$new_window, levels=c("no","yes"))
predictions3 <- predict(model2, mytest, type = "class")
pml_write_files(predictions3)
```

